---
title: "Tarea 1"
author: "Wilmer Gonzalez, Lismar Martin"
date: "19 de junio de 2015"
output: pdf_document
---

## Presentación del problema
Se quiere predecir la clase de un vehiculo de acuerdo a las variables contenidas en el siguiente [repositorio](http://archive.ics.uci.edu/ml/datasets/Car+Evaluation) utilizando Árboles de Decisión tomando en consideración las siguientes clases:

## Clases

Class          | N            |N[%]            |
---------------|:------------:|:--------------:|
   unacc       |   1210       |70.023       | 
   acc         |   384        |22.222       |
   good        |    69        | 3.993       | 
   v-good      |  65          | 3.762       | 
   
Que agrupan las instancias del set de datos.

Se hace uso de los arboles de decisión generados por las funciones J48 y rpart.

## Descripción de las variables

Nombre         | Tipo de Dato | Datos ausentes |Rango                  | Descripción |
---------------|:------------:|:--------------:|:---------------------:|:-----------:|
buying         | Nominal      | No tiene       | vhigh, high, med, log | buying price|
maint          | Nominal      | No tiene       | vhigh, high, med, log | price of the maintenance|
doors          | Nominal      | No tiene       | 2, 3, 4, 5more        | number of doors|
persons        | Nominal      | No tiene       | 2, 4, more            | capacity in terms of persons to carry|
lug_boot       | Nominal      | No tiene       | small, med, big       | the size of luggage boot|
safety         | Nominal      | No tiene       | low, med, high        | estimated safety of the car|

## Carga de las librerias necesarias

En el siguiente script se cargan las librerias necesarias para ejecutar el codigo correspondiente a la tarea. Dicho script simplemente carga o instala(de ser necesario) los paquetes para el estudio mediante un funcion iterativa, gracias a foreach,basada en la llamada require (nativa de R).

```{r echo=T,message=FALSE}
require(devtools)
source_url("https://raw.githubusercontent.com/belgrades/DataMining/master/install.R")
install("rpart.plot")
```

```{r eval=F, ,echo=T}
#Creamos la función que recibe los paquetes
install = function(pkg){
  #Si ya está instalado, no lo instala.
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg)
    if (!require(pkg, character.only = TRUE)) stop(paste("load failure:", pkg))
  }
}

#Instalamos primero "foreach"
install("foreach")

#Seleccionamos los archivos que queremos instalar
archive = c("rJava", "shiny", "rmarkdown", "foreach",
            "caret", "e1071", "rpart", "tree", "RWeka", "C50")
foreach(i = archive) %do% install(i)
```


## Carga de la data
Acá tambien definimos un seed para reproducir los procesos que toman valores aleatorios.

```{r eval=T}
set.seed(1234)
already_save <- grep(pattern ="Datareaded.Rdata",x = dir())
already_save <- class(already_save)
if(class(already_save) == "numeric"){
  load("Datareaded.Rdata")
}else{
  raw_data <- read.csv2(
    file = "http://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data",
    header = F,sep = ",")
  header <- c("buying","maint","doors","persons","lug_boot","safety")
  names(raw_data) <- c(header, "class")
  save(raw_data,file ="Datareaded.Rdata")  
}
```

## Seleccion de variables a utilizar
Para selecionar las variables, estudiamos las clases previamente existentes en el 
data set para evaluar como se caracterizaba con respecto a cada variable

```{r fig.width=30,fig.height=10}
plot(raw_data$safety, raw_data$class)
plot(raw_data$persons, raw_data$class)
plot(raw_data$buying, raw_data$class)
plot(raw_data$maint, raw_data$class)
plot(raw_data$lug_boot, raw_data$class)
plot(raw_data$doors, raw_data$class)
```

Tomando esto en cuenta, decidimos considerar las variables:

* safety
* buying
* persons
* lug_boot

Ya que cada una de estas variables caracteriza la pertenencia a alguna clase.

## Muestreo mediante validación cruzada
Para implementar esta técnica, iteramos 5 veces (que es el numero total de veces que puede ser diferente la particion que tome) seleccionando el
k = 5 dado que 100%(de la data) / 5 = 20%(de la data) por defecto esta eval= F

```{r eval=F}
partitions <- createFolds(y = raw_data$class,k = 5,list = T,returnTrain = F)
for(i in attributes(partitions)){
    training <- raw_data[-partitions$i,]
    test <- raw_data[partitions$i,]
    cat("Model J48 iteración: ",i)
    arbol1 = J48(class~. , test,control = Weka_control(C=0.25 , M = 3))
    plot(arbol1)
    confusionMatrix(arbol1$predictions,test$class)
    cat("Model rpart iteración: ",i)
    arbol2 <- rpart(class ~., training,method = "class")
    library(rpart.plot)
    rpart.plot(arbol2)
    arbol2 <- rpart(class ~., training,method = "class")
    confusionMatrix(predict(arbol2, newData = test, type = "class"), training$class)
    print("---------------------------")
  }  
```

## Muestreo aleatorio

```{r}
indexTraining <- createDataPartition(y = raw_data$class,p = .80,list = FALSE)
nrow(raw_data[indexTraining,])
nrow(raw_data[-indexTraining,])
training <- raw_data[indexTraining,]
test <- raw_data[-indexTraining,]
```

## Aplicación de C4.5 desde RWeka(J48 en Weka)
-
```{r}
arbol1 = J48(class~. , test,control = Weka_control(C=0.25 , M = 3))
plot(arbol1)
confusionMatrix(arbol1$predictions,test$class)
```

## Aplicación del metodo de clasificación desde rpart

### Con variacion de parámetros

Acá obtuvimos diferentes escenarios al modificar los parametros de la función rpart(control)
```{r}
arbol2 <- rpart(class ~., training,method = "class")
minsplits <- c(2,5,10,50,300,1000)
cps <- c(0.3,0.2,0.1,0.0001,0.0000000000001)
minbuckets <- c(2,5,10,50,300)
arbol2_min2_acc <- list()
for (i in minsplits){
  for(j in cps){
    for(k in minbuckets){
      arbol2_min2 <- rpart(class ~., training,method = "class",control = rpart.control(minsplit = i,cp = j, minbucket = k))
      arbol2_min2_conf <- confusionMatrix(predict(arbol2_min2, newData = test, type = "class"), training$class)
      paste("minsplit =",i,",cp =",j,",minbuckets =",k,",accuracy= ",arbol2_min2_conf$overall[1],sep = " ")
      rpart.plot(arbol2_min2)
      arbol2_min2_conf
      arbol2_min2_acc <- rbind(c(arbol2_min2_acc,i,j,k,arbol2_min2_conf$overall[1]))
    }
  }
}
arbol2_min2_acc <- matrix(arbol2_min2_acc,ncol = 4,byrow = T)
nms <-c("minsplits","cp","minbuckets","accuracy")
colnames(arbol2_min2_acc) <- nms
arbol2_min2_acc <- as.data.frame(arbol2_min2_acc)
print(arbol2_min2_acc)
## aca escenarios con mejor precision
arbol2_min2_acc[arbol2_min2_acc$accuracy> 0.97,]

## aca escenarios con peor precision
arbol2_min2_acc[arbol2_min2_acc$accuracy< 0.70,]
```

De lo anterior encontramos que:
* Mayor precisión -> minsplit= 2, cp = 1e-13, minbuckets = 2,  accuracy = 0.9891618.
  NOTA: A este valor se aproximan escenarios con caracteristicas como: minsplit in (2,5,10), minbuckets in (2,5), cp in (0.00001,0.00000000000001).
  De donde notamos que influye en mayor medida la seleccion del minsplit.
  
* Menor precisión -> minsplit= 2, cp = 0.3 , minbuckets = 2, accuracy = 0.699422. 
  NOTA: Sin embargo esta ultima instancia refleja el comportamiento de varias, en donde, el cp == 0.2 ó cp == 0.3 con cualquier otra combinación de variables, al igual que para todas las instacias con minsplit = 1000. Podemos deducir entonces que el crecimiento del minsplit alcance un punto donde el resto de los parametros se ven anuladas por la cantidad de instancias(del estudio) que son permitidas por nodo

### Parámetros por defecto
Acá a pesar que no modificamos los parametros para rpart, el accuracy resulto ser considerablemente alto(0.9422)
donde minsplit = 20, minbucket = 20/3 , cp = 0.1
```{r}
rpart.plot(arbol2)
arbol2 <- rpart(class ~., training, method = "class")
confusionMatrix(predict(arbol2, newData = test, type = "class"), training$class)
print(arbol2_min2_acc)
```
